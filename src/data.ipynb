{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c4e52d",
   "metadata": {},
   "source": [
    "# Laboratorio #5\n",
    "\n",
    "**Esteban Zambrano - 22119**<br>\n",
    "**Edwin Ortega - 22305**<br>\n",
    "**Diego García - 22404**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f812f",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69a15b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "['id', 'keyword', 'location', 'text', 'target']\n",
      "id          0.0000\n",
      "keyword     0.0080\n",
      "location    0.3327\n",
      "text        0.0000\n",
      "target      0.0000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "df = pd.read_csv(DATA_DIR / \"train.csv\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "print(df.isna().mean().round(4))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09f1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valida que vengan las columnas esperadas\n",
    "expected = {\"id\",\"keyword\",\"location\",\"text\",\"target\"}\n",
    "missing = expected - set(df.columns)\n",
    "assert not missing, f\"Faltan columnas: {missing}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd052f3c",
   "metadata": {},
   "source": [
    "### Limpieza y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e291e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "KEEP_911 = True\n",
    "REMOVE_NUMBERS = True\n",
    "APPLY_STOPWORDS = True\n",
    "\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "    STOP = set(stopwords.words(\"english\"))\n",
    "except Exception:\n",
    "    try:\n",
    "        from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "        STOP = set(ENGLISH_STOP_WORDS)\n",
    "    except Exception:\n",
    "        STOP = set()\n",
    "\n",
    "if \"df\" not in globals():\n",
    "    df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ccec6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patrones regex y funciones de limpieza\n",
    "\n",
    "URL_PATTERN     = re.compile(r\"http[s]?://\\S+|www\\.\\S+\")\n",
    "HTML_PATTERN    = re.compile(r\"<.*?>\")\n",
    "HANDLE_PATTERN  = re.compile(r\"@\\w+\")\n",
    "HASHTAG_PATTERN = re.compile(r\"#(\\w+)\")\n",
    "EMOJI_PATTERN   = re.compile(\"[\" # rangos Unicode de emojis\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticonos\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # símbolos\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transporte/mapas\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # banderas\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def _remove_numbers(text: str) -> str:\n",
    "    if not REMOVE_NUMBERS:\n",
    "        return text\n",
    "    if KEEP_911:\n",
    "        # elimina números aislados, excepto 911\n",
    "        return re.sub(r\"\\b(?!911\\b)\\d+\\b\", \" \", text)\n",
    "    # elimina todos los números\n",
    "    return re.sub(r\"\\d+\", \" \", text)\n",
    "\n",
    "def clean_text_basic(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Pasos: \n",
    "      1) minúsculas \n",
    "      2) quitar URLs y HTML\n",
    "      3) quitar @handles y '#', conservando la palabra del hashtag\n",
    "      4) quitar emojis\n",
    "      5) quitar números (con opción de conservar 911)\n",
    "      6) quitar puntuación\n",
    "      7) colapsar espacios\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = \"\" if pd.isna(s) else str(s)\n",
    "\n",
    "    x = s.lower()\n",
    "    x = URL_PATTERN.sub(\" \", x)\n",
    "    x = HTML_PATTERN.sub(\" \", x)\n",
    "    x = HANDLE_PATTERN.sub(\" \", x)\n",
    "    x = HASHTAG_PATTERN.sub(r\"\\1\", x)\n",
    "    x = EMOJI_PATTERN.sub(\" \", x)\n",
    "    x = _remove_numbers(x)\n",
    "    x = x.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "    return x\n",
    "\n",
    "def remove_stopwords(s: str) -> str:\n",
    "    if not APPLY_STOPWORDS or not STOP:\n",
    "        return s\n",
    "    toks = s.split()\n",
    "    toks = [t for t in toks if t not in STOP]\n",
    "    return \" \".join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69eb8bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deeds reason earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>rockyfire update california hwy closed directi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>flood disaster heavy rain causes flash floodin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>im hill woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>theres emergency evacuation happening building...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>im afraid tornado coming area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  I'm on top of the hill and I can see a fire in...   \n",
       "8  There's an emergency evacuation happening now ...   \n",
       "9  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "                                          clean_text  \n",
       "0              deeds reason earthquake allah forgive  \n",
       "1                   forest near la ronge sask canada  \n",
       "2  residents asked shelter place notified officer...  \n",
       "3  people receive wildfires evacuation orders cal...  \n",
       "4  just got sent photo ruby alaska smoke wildfire...  \n",
       "5  rockyfire update california hwy closed directi...  \n",
       "6  flood disaster heavy rain causes flash floodin...  \n",
       "7                                      im hill woods  \n",
       "8  theres emergency evacuation happening building...  \n",
       "9                      im afraid tornado coming area  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar la limpieza y crear clean_text\n",
    "assert {\"text\",\"target\"}.issubset(df.columns), \"Columnas esperadas no encontradas.\"\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].map(clean_text_basic).map(remove_stopwords)\n",
    "\n",
    "# Vista rápida de la limpieza\n",
    "df[[\"text\", \"clean_text\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b55163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con dígitos remanentes: 4\n"
     ]
    }
   ],
   "source": [
    "# Quitar digitos dentro de tokens, preservando '911' como token completo\n",
    "\n",
    "def strip_digits_preserve_911(text: str) -> str:\n",
    "    toks = text.split()\n",
    "    out = []\n",
    "    for t in toks:\n",
    "        if t == \"911\":\n",
    "            out.append(t)\n",
    "        else:\n",
    "            t2 = re.sub(r\"\\d+\", \"\", t)  # quita dígitos embebidos\n",
    "            if t2:  # descarta tokens vacíos\n",
    "                out.append(t2)\n",
    "    return \" \".join(out)\n",
    "\n",
    "df[\"clean_text\"] = df[\"clean_text\"].map(strip_digits_preserve_911)\n",
    "\n",
    "# Verificación rápida\n",
    "rem = df[\"clean_text\"].str.contains(r\"\\d\").sum()\n",
    "print(f\"Filas con dígitos remanentes: {rem}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a624b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con dígitos (excluyendo el token '911'): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, clean_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reporta filas con dígitos que NO sean el token 911\n",
    "def has_non911_digits(s: str) -> bool:\n",
    "    toks = s.split()\n",
    "    for t in toks:\n",
    "        if any(ch.isdigit() for ch in t) and t != \"911\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "mask_bad = df[\"clean_text\"].map(has_non911_digits)\n",
    "print(\"Filas con dígitos (excluyendo el token '911'):\", int(mask_bad.sum()))\n",
    "\n",
    "# Ver ejemplos si hubiera alguno:\n",
    "df.loc[mask_bad, [\"text\",\"clean_text\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f287a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen dataset:\n",
      " {\n",
      "  \"rows\": 7613,\n",
      "  \"nulls_pct\": {\n",
      "    \"id\": 0.0,\n",
      "    \"keyword\": 0.008,\n",
      "    \"location\": 0.3327,\n",
      "    \"text\": 0.0,\n",
      "    \"target\": 0.0,\n",
      "    \"clean_text\": 0.0\n",
      "  }\n",
      "}\n",
      "\n",
      "Len (caracteres) - antes:\n",
      " {\n",
      "  \"count\": 7613.0,\n",
      "  \"mean\": 101.04,\n",
      "  \"std\": 33.78,\n",
      "  \"min\": 7.0,\n",
      "  \"25%\": 78.0,\n",
      "  \"50%\": 107.0,\n",
      "  \"75%\": 133.0,\n",
      "  \"max\": 157.0\n",
      "}\n",
      "\n",
      "Len (caracteres) - después:\n",
      " {\n",
      "  \"count\": 7613.0,\n",
      "  \"mean\": 57.24,\n",
      "  \"std\": 24.03,\n",
      "  \"min\": 0.0,\n",
      "  \"25%\": 40.0,\n",
      "  \"50%\": 58.0,\n",
      "  \"75%\": 75.0,\n",
      "  \"max\": 138.0\n",
      "}\n",
      "\n",
      "Len (palabras) - antes:\n",
      " {\n",
      "  \"count\": 7613.0,\n",
      "  \"mean\": 14.9,\n",
      "  \"std\": 5.73,\n",
      "  \"min\": 1.0,\n",
      "  \"25%\": 11.0,\n",
      "  \"50%\": 15.0,\n",
      "  \"75%\": 19.0,\n",
      "  \"max\": 31.0\n",
      "}\n",
      "\n",
      "Len (palabras) - después:\n",
      " {\n",
      "  \"count\": 7613.0,\n",
      "  \"mean\": 8.26,\n",
      "  \"std\": 3.39,\n",
      "  \"min\": 0.0,\n",
      "  \"25%\": 6.0,\n",
      "  \"50%\": 8.0,\n",
      "  \"75%\": 11.0,\n",
      "  \"max\": 21.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Métricas de impacto de la limpieza\n",
    "stats = {\n",
    "    \"rows\": len(df),\n",
    "    \"nulls_pct\": df.isna().mean().round(4).to_dict(),\n",
    "}\n",
    "lens_before_chars = df[\"text\"].astype(str).str.len().describe().round(2).to_dict()\n",
    "lens_after_chars  = df[\"clean_text\"].astype(str).str.len().describe().round(2).to_dict()\n",
    "lens_before_words = df[\"text\"].astype(str).str.split().map(len).describe().round(2).to_dict()\n",
    "lens_after_words  = df[\"clean_text\"].astype(str).str.split().map(len).describe().round(2).to_dict()\n",
    "\n",
    "print(\"Resumen dataset:\\n\", json.dumps(stats, indent=2))\n",
    "print(\"\\nLen (caracteres) - antes:\\n\", json.dumps(lens_before_chars, indent=2))\n",
    "print(\"\\nLen (caracteres) - después:\\n\", json.dumps(lens_after_chars, indent=2))\n",
    "print(\"\\nLen (palabras) - antes:\\n\", json.dumps(lens_before_words, indent=2))\n",
    "print(\"\\nLen (palabras) - después:\\n\", json.dumps(lens_after_words, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71764cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: ..data/train_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar dataset limpio\n",
    "Path(\"../data\").mkdir(exist_ok=True, parents=True)\n",
    "df.to_csv(\"../data/train_clean.csv\", index=False)\n",
    "print(\"Guardado: ..data/train_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f77fa",
   "metadata": {},
   "source": [
    "| Parámetro / Decisión  | Valor / Descripción                                                                 |\n",
    "| --------------------- | ----------------------------------------------------------------------------------- |\n",
    "| KEEP\\_911             | `True` → se elimina todo número excepto el token completo `\"911\"`                   |\n",
    "| REMOVE\\_NUMBERS       | `True` → números eliminados (sueltos o embebidos en palabras)                       |\n",
    "| APPLY\\_STOPWORDS      | `True` → stopwords en inglés eliminadas (NLTK; fallback a scikit-learn si no carga) |\n",
    "| Minúsculas            | Sí, todo el texto se convierte a minúsculas                                         |\n",
    "| URLs y HTML           | Eliminados con expresiones regulares                                                |\n",
    "| @handles              | Eliminados completamente                                                            |\n",
    "| #hashtags             | Se elimina `#` pero se conserva la palabra (`#wildfire → wildfire`)                 |\n",
    "| Emojis                | Eliminados (rangos Unicode de emoticones, símbolos, banderas, etc.)                 |\n",
    "| Signos de puntuación  | Eliminados con `string.punctuation`                                                 |\n",
    "| Espacios múltiples    | Normalizados a un único espacio                                                     |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
